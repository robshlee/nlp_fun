{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Fun\n",
    "In this notebook I'll be practicing NLP techniques. The goal for the provided dataset is to classify randomly selected tweets from political officials and classify them into whether or not they are partisan tweets or neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>audience</th>\n",
       "      <th>audience:confidence</th>\n",
       "      <th>bias</th>\n",
       "      <th>bias:confidence</th>\n",
       "      <th>message</th>\n",
       "      <th>...</th>\n",
       "      <th>orig__golden</th>\n",
       "      <th>audience_gold</th>\n",
       "      <th>bias_gold</th>\n",
       "      <th>bioid</th>\n",
       "      <th>embed</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>message_gold</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>766192484</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:17</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partisan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R000596</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>3.83249E+17</td>\n",
       "      <td>From: Trey Radel (Representative from Florida)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>766192485</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:20</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partisan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>attack</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M000355</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>3.11208E+17</td>\n",
       "      <td>From: Mitch McConnell (Senator from Kentucky)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>766192486</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:14</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>support</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S001180</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>3.39069E+17</td>\n",
       "      <td>From: Kurt Schrader (Representative from Oregon)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>766192487</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:08</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C000880</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>2.98528E+17</td>\n",
       "      <td>From: Michael Crapo (Senator from Idaho)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>766192488</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:26</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partisan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U000038</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>4.07643E+17</td>\n",
       "      <td>From: Mark Udall (Senator from Colorado)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  766192484    False   finalized                   1      8/4/15 21:17   \n",
       "1  766192485    False   finalized                   1      8/4/15 21:20   \n",
       "2  766192486    False   finalized                   1      8/4/15 21:14   \n",
       "3  766192487    False   finalized                   1      8/4/15 21:08   \n",
       "4  766192488    False   finalized                   1      8/4/15 21:26   \n",
       "\n",
       "   audience  audience:confidence      bias  bias:confidence  message  \\\n",
       "0  national                  1.0  partisan              1.0   policy   \n",
       "1  national                  1.0  partisan              1.0   attack   \n",
       "2  national                  1.0   neutral              1.0  support   \n",
       "3  national                  1.0   neutral              1.0   policy   \n",
       "4  national                  1.0  partisan              1.0   policy   \n",
       "\n",
       "                         ...                          orig__golden  \\\n",
       "0                        ...                                   NaN   \n",
       "1                        ...                                   NaN   \n",
       "2                        ...                                   NaN   \n",
       "3                        ...                                   NaN   \n",
       "4                        ...                                   NaN   \n",
       "\n",
       "   audience_gold  bias_gold    bioid  \\\n",
       "0            NaN        NaN  R000596   \n",
       "1            NaN        NaN  M000355   \n",
       "2            NaN        NaN  S001180   \n",
       "3            NaN        NaN  C000880   \n",
       "4            NaN        NaN  U000038   \n",
       "\n",
       "                                               embed           id  \\\n",
       "0  <blockquote class=\"twitter-tweet\" width=\"450\">...  3.83249E+17   \n",
       "1  <blockquote class=\"twitter-tweet\" width=\"450\">...  3.11208E+17   \n",
       "2  <blockquote class=\"twitter-tweet\" width=\"450\">...  3.39069E+17   \n",
       "3  <blockquote class=\"twitter-tweet\" width=\"450\">...  2.98528E+17   \n",
       "4  <blockquote class=\"twitter-tweet\" width=\"450\">...  4.07643E+17   \n",
       "\n",
       "                                              label message_gold   source  \\\n",
       "0    From: Trey Radel (Representative from Florida)          NaN  twitter   \n",
       "1     From: Mitch McConnell (Senator from Kentucky)          NaN  twitter   \n",
       "2  From: Kurt Schrader (Representative from Oregon)          NaN  twitter   \n",
       "3          From: Michael Crapo (Senator from Idaho)          NaN  twitter   \n",
       "4          From: Mark Udall (Senator from Colorado)          NaN  twitter   \n",
       "\n",
       "                                                text  \n",
       "0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...  \n",
       "1  VIDEO - #Obamacare:  Full of Higher Costs and ...  \n",
       "2  Please join me today in remembering our fallen...  \n",
       "3  RT @SenatorLeahy: 1st step toward Senate debat...  \n",
       "4  .@amazon delivery #drones show need to update ...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/political_media.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I'm really just concerned with the bias and text columns for predicting the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partisan</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partisan</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>partisan</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias                                               text\n",
       "0  partisan  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...\n",
       "1  partisan  VIDEO - #Obamacare:  Full of Higher Costs and ...\n",
       "2   neutral  Please join me today in remembering our fallen...\n",
       "3   neutral  RT @SenatorLeahy: 1st step toward Senate debat...\n",
       "4  partisan  .@amazon delivery #drones show need to update ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine df\n",
    "df = pd.read_csv('datasets/political_media.csv',usecols=[7,20])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binarize bias column for 1 being partisan\n",
    "df['bias'] = df['bias'].apply(lambda x: 1 if x == 'partisan' else 0)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].values,\n",
    "                                                   df['bias'].values, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27226666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See % of partisan from training set \n",
    "# This is also baseline accuracy for predicting partisan\n",
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Time\n",
    "I'll try a couple different techniques here starting with CountVectorizer. We'll be using my favorite model, Random Forest Classifier to make predictions for this dataset to compare how setting up the sparse matrix can affect the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer()\n",
    "CountVectorizer takes a set of words and splits them up into one column per word with the count of the words for that row in that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction score:  0.7648\n",
      "[[918  42]\n",
      " [252  38]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.96      0.86       960\n",
      "          1       0.47      0.13      0.21       290\n",
      "\n",
      "avg / total       0.71      0.76      0.71      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_cv, y_train)\n",
    "\n",
    "predictions = rfc.predict(X_test_cv)\n",
    "\n",
    "print('Test prediction score: ', rfc.score(X_test_cv, y_test))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our model classified 96% of the total neutral tweets correctly which is pretty awesome.. but it only classified 13% of the total partisan tweets correctly. Looking at the precision, our model is still doing much better than baseline which was at 27%.\n",
    "\n",
    "Let's take a peak at what the sparse matrix looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (3750, 15366)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0017a43b2370</th>\n",
       "      <th>001a4bcf6878</th>\n",
       "      <th>00am</th>\n",
       "      <th>00kq8qqlaa</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>010914</th>\n",
       "      <th>...</th>\n",
       "      <th>űşm</th>\n",
       "      <th>űşneil</th>\n",
       "      <th>űşre</th>\n",
       "      <th>űşs</th>\n",
       "      <th>űşshistorymonth</th>\n",
       "      <th>űşt</th>\n",
       "      <th>űşve</th>\n",
       "      <th>űť</th>\n",
       "      <th>űťimproper</th>\n",
       "      <th>űź</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000th  0017a43b2370  001a4bcf6878  00am  00kq8qqlaa  00pm  01  \\\n",
       "0   0    0      0             0             0     0           0     0   0   \n",
       "1   0    0      0             0             0     0           0     0   0   \n",
       "2   0    0      0             0             0     0           0     0   0   \n",
       "3   0    0      0             0             0     0           0     0   0   \n",
       "4   0    0      0             0             0     0           0     0   0   \n",
       "\n",
       "   010914 ...  űşm  űşneil  űşre  űşs  űşshistorymonth  űşt  űşve  űť  \\\n",
       "0       0 ...    0       0     0    0                0    0     0   1   \n",
       "1       0 ...    0       0     0    0                0    0     0   0   \n",
       "2       0 ...    0       0     0    0                0    0     0   0   \n",
       "3       0 ...    0       0     0    0                0    0     0   0   \n",
       "4       0 ...    0       0     0    0                0    0     0   0   \n",
       "\n",
       "   űťimproper  űź  \n",
       "0           0   0  \n",
       "1           0   0  \n",
       "2           0   0  \n",
       "3           0   0  \n",
       "4           0   0  \n",
       "\n",
       "[5 rows x 15366 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train shape: ', pd.DataFrame(X_train_cv.todense()).shape)\n",
    "pd.DataFrame(X_train_cv.todense(), columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall pretty massive matrix- which is expected with count vectorizing words in NLP. \n",
    "\n",
    "Let's run the model once more with setting the min_df and max_df parameters. These 2 parameters ignore terms that have a documment frequency strictly lower/higher than the given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction score:  0.7176\n",
      "[[841 119]\n",
      " [234  56]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.83       960\n",
      "          1       0.32      0.19      0.24       290\n",
      "\n",
      "avg / total       0.68      0.72      0.69      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0.10, max_df=0.90)\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_cv, y_train)\n",
    "\n",
    "predictions = rfc.predict(X_test_cv)\n",
    "\n",
    "print('Test prediction score: ', rfc.score(X_test_cv, y_test))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these results are a bit interesting. By tuning the parameters, our model got a small boost in predicting the partisan tweets correctly. There was a tradeoff however as the predictive power for classifying neutral tweets suffered slightly.\n",
    "\n",
    "Still- with classifying only 19% of the total partisan tweets correctly I think we can make more adjustments to get a good boost for our model. Let's try to remove stop words next!\n",
    "\n",
    "As soem words are very commmon and provide no information on the text content, we can remove them with the stop words parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction score:  0.7432\n",
      "[[860 100]\n",
      " [221  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.90      0.84       960\n",
      "          1       0.41      0.24      0.30       290\n",
      "\n",
      "avg / total       0.71      0.74      0.72      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_cv, y_train)\n",
    "\n",
    "predictions = rfc.predict(X_test_cv)\n",
    "\n",
    "print('Test prediction score: ', rfc.score(X_test_cv, y_test))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an overall accuracy standpoint this model performed slightly worse than our no-parameter count vectorizer model. Comparing off the 2 models, the decision to choose between them may be decided by what you would deem more important. Better to have type 1 errors or type 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### TfidVectorizer()\n",
    "\n",
    "Let's take a step away from count vectorizer and try to classify these tweets through TFIDF or term frequency - inverse document frequency. Fancy jargon for classifying by looking for words that occur a lot in one document but doesn't occur in other documments as often.\n",
    "\n",
    "Breaking it down further termm frequency is the frequency of a certain term in a document. Inverse document frequency is defined as the frequency of documents that contain that termm over the whole corpus. \n",
    "\n",
    "Can be defined as,\n",
    "$$ tf(t, d) = \\frac{N_{term}}{N_{document}} $$\n",
    "\n",
    "$$ idf(t, D) = log(\\frac{N_{documents}}{N_{\\text{documents that contain term t}}}) $$\n",
    "\n",
    "Enough talking- let's model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764\n",
      "[[890  70]\n",
      " [225  65]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.93      0.86       960\n",
      "          1       0.48      0.22      0.31       290\n",
      "\n",
      "avg / total       0.72      0.76      0.73      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "# We'll use stop words because.. it just makes too much sense.\n",
    "tvec.fit(X_train)\n",
    "\n",
    "X_train_tvec = tvec.transform(X_train)\n",
    "X_test_tvec = tvec.transform(X_test)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_tvec, y_train)\n",
    "print(rfc.score(X_test_tvec, y_test))\n",
    "predictions = rfc.predict(X_test_tvec)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our initial model with CountVectorizer yielded us an accuracy of 76.48%, so nearly identical to the accuracy of the tfidf model. The precision scores for both neutral and partisan were higher than the original model, so when this model predicted neutral or partisan it was correct more often than our previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly all of our models were very similar in accuracy scores. Choosing between themm would be a question whether you deem type 1 or type 2 errors more impmortant. As next steps several things I could have tried are custom stop word lists, use dimmensionality reduction technique (like TruncatedSVD), optimizing hyperparameters (maybe gridsearch), and just different classification models like logistic regression or K nearest neighbors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
